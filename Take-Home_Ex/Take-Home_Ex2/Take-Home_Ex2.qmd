---
title: "Take-Home Exercise 2: Regionalisation with Spatially Constrained Cluster Analysis"
editor: visual
format:
  html:
    code-fold: true
    code-summary: "Show the code"
---

## Overview

For this take-home exercise, we would be exploring the concept of regionalisation with clustering analysis using a multivariate analysis on Nigeria's waterpoints. With clustering, we hope to be able to uncover multiple variables pairing that might point to a certain phenomena happening at one region of the country.

## Getting Started

As usual, to get started, we will load the necessary R packages. For the purpose of this in-class exercise, multiple R packages will be used, they are:

-   

    -   Spatial data handling

        -   **sf**, **rgdal** and **spdep**

    -   Attribute data handling

        -   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

    -   Choropleth mapping

        -   **tmap**

    -   Multivariate data visualisation and analysis

        -   **coorplot**, **ggpubr**, **GGAlly**, and **heatmaply**

    -   Cluster analysis

        -   **cluster**

        -   **ClustGeo**

        -   **NbClust**

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally,funModeling)
```

```{r}
#| eval: false
#command above make sure quarto does not execute
wp <- st_read(dsn = "geodata",
        layer = "geo_export",
        crs = 4326) %>%
  filter(clean_coun == "Nigeria")
```

```{r}
#| eval: false
wp_sf <- st_sf(wp, crs=4326) 
```

```{r}
#| eval: false
nga <- st_read(dsn = "geodata",
              layer = "geoboundaries-NGA-ADM2")
```

## Data Wrangling

### Handling Duplicates

Below codes are referenced from our exemplary classmate Jordan ([link](https://jordan-isss624-geospatial.netlify.app/posts/geo/geospatial_exercise/#data-wrangling)), recommended by prof Kam.

```{r}
#| eval: false
nigeria <- (nga[order(nga$shapeName), ])

duplicate_area <- nigeria$shapeName[ nigeria$shapeName %in% nigeria$shapeName[duplicated(nigeria$shapeName)] ]

duplicate_area

```

```{r}
#| eval: false
tmap_mode("view")

tm_shape(nigeria[nigeria$shapeName %in% duplicate_area,]) +
  tm_view(set.zoom.limits = c(5,9))+
  tm_polygons()

```

```{r}
#| eval: false
nigeria$shapeName[c(94,95,304,305,355,356,519,546,547,693,694)] <- c("Bassa (Kogi)","Bassa (Plateau)",
                                                                               "Ifelodun (Kwara)","Ifelodun (Osun)",
                                                                               "Irepodun (Kwara)","Irepodun (Osun)",
                                                                               "Nassarawa","Obi (Benue)","Obi(Nasarawa)",
                                                                               "Surulere (Lagos)","Surulere (Oyo)")

length((nigeria$shapeName[ nigeria$shapeName %in% nigeria$shapeName[duplicated(nigeria$shapeName)] ]))
```

Here we replaced NA values with "Unknown" to help facilitate processing

```{r}
#| eval: false
wp_sf <- st_join(wp_sf, nigeria)  %>%
  mutate(status_cle=replace_na(status_cle,"Unknown"))
```

## Exploratory Data Analysis

First we look at the distribution of waterpoints based on their operational status

```{r}
#| eval: false
freq(data=wp_sf,
     input = 'status_cle')
```

## ![](images/paste-B49516A2.png)

```{r}
#| eval: false
wpt_functional <- wp_sf %>%
  filter(status_cle %in%
           c("Functional",
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
#| eval: false
wpt_nonfunctional <- wp_sf %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r}
#| eval: false
freq(data=wpt_nonfunctional, 
     input = 'status_cle')
```

![](images/paste-3EF04571.png)

Here we can see that hand pumps are a overwhelming potential for the type of water point so we will carry on using hand pump waterpoints as a variable.

```{r}
#| eval: false
freq(data=wp_sf, 
     input = 'water_te_2')
```

![](images/paste-4D691D64.png)

As there are some Hand Pumps that are labelled slightly differently, we have to use `str_detect` from `stringr` library to do a wildcard detection where we filter for anything that contains "Hand Pump"

```{r}
#| eval: false
wpt_handpump <- wp_sf %>%
  filter(str_detect(water_te_2, "Hand Pump"))
```

```{r}
#| eval: false
freq(data=wpt_handpump, 
     input = 'water_te_2')
```

![](images/paste-157C6827.png)

Here we can see the general distribution is that the usage cap or limit is 1000 or below 1000.

```{r}
#| eval: false
freq(data=wp_sf, 
     input = 'usage_cap')
```

![](images/paste-78CA827C.png)

Next we divide them and take a look if our previous split is correct

```{r}
#| eval: false
wpt_usage_abv_1000 <- wp_sf %>%
  filter(`usage_cap` >= 1000)
```

```{r}
#| eval: false
wpt_usage_less_1000 <- wp_sf %>%
  filter(`usage_cap` < 1000)
```

```{r}
#| eval: false
freq(data=wpt_usage_less_1000, 
     input = 'usage_cap')
```

![](images/paste-9C835C80.png)

Then we take a look at how much of the area is considered rural (is_urban = False)

```{r}
#| eval: false
freq(data=wp_sf, 
     input = 'is_urban')
```

![](images/paste-DFD9B889.png)

```{r}
#| eval: false
wpt_rural <- wp_sf %>%
  filter(`is_urban` == "False")
```

```{r}
#| eval: false
freq(data=wpt_rural, 
     input = 'is_urban')
```

![](images/paste-03131751.png)

For this part, we get the number of water points and their respective figures in each LGA by using the `mutate` function along with `lengths` and `st_intercepts`

```{r}
#| eval: false
nga_wp <- nigeria %>% 
  mutate(`total wpt` = lengths(
    st_intersects( nigeria,wp_sf))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nigeria, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nigeria, wpt_nonfunctional))) %>%
  mutate(`wpt_handpump` = lengths(
    st_intersects(nigeria, wpt_handpump))) %>%
  mutate(`wpt usage_cap 1000` = lengths(
    st_intersects(nigeria, wpt_usage_abv_1000))) %>%
  mutate(`wpt usage_cap below 1000` = lengths(
    st_intersects(nigeria, wpt_usage_less_1000))) %>%
  mutate(`wpt rural` = lengths(
    st_intersects(nigeria, wpt_rural)))
```

This file is then saved:

```{r}
#| eval: false
write_rds(nga_wp, "geodata/nga_wp.rds")
```

Here we read in the saved file while also removing the na fields for functional and non functional water points

```{r}
nga_wp <- read_rds("geodata/nga_wp.rds")
nga_wp <- nga_wp %>%
  filter(`total wpt` > 0) %>%
  mutate(`wpt non-functional` = replace_na(`wpt non-functional`, 0)) %>%
  mutate(`wpt functional` = replace_na(`wpt functional`, 0))
```

```{r}
tmap_mode("plot")
nga_wp <- st_transform(nga_wp, 
                              crs = 26391)
total <- tm_shape(nga_wp) +
  tm_fill("total wpt",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "total",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
wp_functional <- tm_shape(nga_wp) +
  tm_fill("wpt functional",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "functional",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
wp_nonfunctional <- tm_shape(nga_wp) +
  tm_fill("wpt non-functional",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "non-functional",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
handpump <- tm_shape(nga_wp) +
  tm_fill("wpt_handpump",
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "handpump",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
usageabv <- tm_shape(nga_wp) +
  tm_fill("wpt usage_cap 1000",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "usage cap 1000",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
usagebelow <- tm_shape(nga_wp) +
  tm_fill("wpt usage_cap below 1000",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "usage cap < 1000",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
rural <- tm_shape(nga_wp) +
  tm_fill("wpt rural",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "rural waterpoints",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)

tmap_arrange(total, wp_functional, asp=1, ncol=2)
```

```{r}
tmap_arrange(wp_nonfunctional, handpump, asp=1, ncol=2)
```

```{r}
tmap_arrange(usageabv,usagebelow, asp=1, ncol=2)
```

We can see from below if total water points and rural water points are used for comparison, they look about the same, therefore it could be better to look at the percentage

```{r}
tmap_arrange(total,rural,asp=1, ncol=2)
```

```{r}
nga_wp <- nga_wp %>%
  mutate(pct_functional = case_when(
    `wpt functional` == 0 ~ 0,
    TRUE ~ `wpt functional`/`total wpt`
    )) %>%
  mutate(pct_nonfunctional = case_when(
    `wpt non-functional` == 0 ~ 0,
    TRUE ~ `wpt non-functional`/`total wpt`
    )) %>%
  mutate(pct_handpump = case_when(
    `wpt_handpump` == 0 ~ 0,
    TRUE ~ `wpt_handpump`/`total wpt`
    )) %>%
  mutate(pct_rural = case_when(
    `wpt non-functional` == 0 ~ 0,
    TRUE ~ `wpt rural`/`total wpt`
    )) %>%
  mutate(pct_usage1000 = case_when(
    `wpt non-functional` == 0 ~ 0,
    TRUE ~ `wpt usage_cap 1000`/`total wpt`
    )) %>%
  mutate(pct_usage_below_1000 = case_when(
    `wpt non-functional` == 0 ~ 0,
    TRUE ~ `wpt usage_cap below 1000`/`total wpt`
    )) 
```

```{r}
pct_functional <- tm_shape(nga_wp) +
  tm_fill("pct_functional",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "functional",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
pct_nonfunctional <- tm_shape(nga_wp) +
  tm_fill("pct_nonfunctional",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "non-functional",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
pct_handpump <- tm_shape(nga_wp) +
  tm_fill("pct_handpump",
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Percentage of handpumps",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
pct_usageabv <- tm_shape(nga_wp) +
  tm_fill("pct_usage1000",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Percentage of waterpoints usage = 1000",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
pct_usagebelow <- tm_shape(nga_wp) +
  tm_fill("pct_usage_below_1000",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Percentage of waterpoints usage below 1000",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)
pct_rural <- tm_shape(nga_wp) +
  tm_fill("pct_rural",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Percentage of waterpoint that are rural",legend.height = 0.25, main.title.size = 0.8,
            legend.width = 0.35)

tmap_arrange(pct_functional, pct_nonfunctional, pct_handpump,pct_usageabv,pct_usagebelow, pct_rural, asp=1, ncol=2)
```

```{r}
tmap_arrange(pct_functional, pct_nonfunctional, asp=1, ncol=2)
```

```{r}
tmap_arrange(pct_usageabv,pct_usagebelow, asp=1, ncol=2)
```

Percentage for rural water points and total paints a different picture compared to the absolute number of rural water points seen above

```{r}
tmap_arrange(total, pct_rural, asp=1, ncol=2)
```

### Summary Statistics

Below we see the summary statistics for the dataframe and the various plots to see the summary statistics of each variable

```{r}
summary(nga_wp)
```

```{r}
func <- ggplot(data=nga_wp, 
             aes(x= `wpt functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

nonfunc <- ggplot(data=nga_wp, 
             aes(x= `wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
ggarrange(func , nonfunc,
          ncol = 2, 
          nrow = 1)
```

```{r}
func <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

nonfunc <- ggplot(data=nga_wp, 
             aes(x= `pct_nonfunctional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

handp <- ggplot(data=nga_wp, 
             aes(x= `pct_handpump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

usagehigh <- ggplot(data=nga_wp, 
             aes(x= `pct_usage1000`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

usagelow <- ggplot(data=nga_wp, 
             aes(x= `pct_usage_below_1000`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

rural <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")


ggarrange(func , nonfunc, handp , usagehigh, usagelow, rural, ncol = 3,nrow = 2)
```

### Correlation analysis

Set geometry column to null for correlation analysis

```{r}
nga_wp$"wpt functional" <- as.numeric(nga_wp$"wpt functional")
nga_wp$"wpt non-functional" <- as.numeric(nga_wp$"wpt non-functional")
nga_wp_nogeo <- nga_wp %>%
  st_set_geometry(NULL) %>%
  select("shapeName", "wpt non-functional", "wpt functional", "pct_functional","pct_nonfunctional", "pct_handpump", "pct_usage_below_1000","pct_usage1000", "pct_rural")
head(nga_wp_nogeo,10)
```

```{r}
cluster_vars.cor = cor(nga_wp_nogeo[,2:9])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",,number.cex=0.5,
               diag = "l",
               tl.col = "black")
```

We can see from the correlation plot here that the usage percentage above 1000 and below 1000 are highly correlated, that is probably because if the usage is not \>=1000, then it will belong in the other category. This likely means that only one should be used for cluster analysis, in this case we will be dropping percentage of water point with usage \>=1000 and using the one that is below 1000.

## Hierarchy Cluster Analysis

### Extracting clustering variables

```{r}

cluster_vars <- nga_wp_nogeo %>%
  select("shapeName", "wpt non-functional", "wpt functional", "pct_functional","pct_nonfunctional", "pct_handpump", "pct_usage_below_1000", "pct_rural")
head(cluster_vars,10)
```

In the code below, we first change the row name to be same as "shapeName" which is the area name and then we remove the column

```{r}
row.names(cluster_vars) <- cluster_vars$"shapeName"
nga_wp_analysis <- select(cluster_vars, c(2:8))
head(nga_wp_analysis, 10)
```

### Data Standardisation

Since, we can see from above, the number of functional and non-functional water points are not standardised, we would need to perform data standardisation for these 2 columns. They are also not normally distributed so we will be performing min-max standardisation here as we want our data to be still in the same scale as those in percentage.

```{r}
nga_wp_analysis.std <- nga_wp_analysis %>%
  normalize(nga_wp_analysis[,1:2])
#left_join(nga_wp_analysis.std,nga_wp_analysis[,3:7], by = "row")
summary(nga_wp_analysis.std)
```

### Visualising the standardised clustering variables

We can see from the distribution below for the right plot that the non-functional water points field has been normalised to values between 0 and 1(without change in distribution) instead of the non-standardised values in the plot on the left.

```{r}
r <- ggplot(data=nga_wp_analysis, 
             aes(x= `wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

analysis_df <- as.data.frame(nga_wp_analysis.std)
s <- ggplot(data=analysis_df, 
       aes(x=`wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

ggarrange(r, s,
          ncol =2,
          nrow = 1)
```

### Computing proximity matrix

Considering we are measuring geometric distance and based on grids, euclidean distance is chosen as the method.

```{r}
proxmat <- dist(nga_wp_analysis.std, method = 'euclidean')
```

### Computing hierarchical clustering

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

```{r}
plot(hclust_ward, cex = 0.6)
```

### Selecting the optimal clustering algorithm

For hierarchical clustering, there are various ways to sequence the clustering. Due to that, it can sometimes be hard to pick which is the better option for the given dataset. Therefore in order to pick out the most suitable clustering technique, we use the agnes() function of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package. This function will help pick out the best clustering structure based on the agglomerative coefficent where 1 would be the best score.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(nga_wp_analysis.std, method = x)$ac
}

map_dbl(m, ac)
```

As we see above, ward's method presents the best clustering structure with a score of 0.99. Therefore, we would proceed with ward's method for subsequent analysis.

### Determining Optimal Clusters

Determining the number of optimal cluster is also another difficult challenge in the realm of clustering. For this, we'll be using the gap statistic method, which is sort of similar to elbow method for choosing the optimal number of clusters. To compute the gap statistic, [*clusGap()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/clusGap) of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package will be used. We specify max number of clusters to be 10, and number of monte carlo sampling to be [**500**]{.underline} as recommended by the documentation.

```{r}
set.seed(12345)
gap_stat <- clusGap(nga_wp_analysis.std, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 500)
# Print the result
print(gap_stat, method = "firstmax")
```

```{r}
fviz_gap_stat(gap_stat)
```

```{r}
print(gap_stat, method = "globalSEmax")
```

Both the firstmax and globalSEmax methods agree that the optimal number of clusters is 10, however it seems that the number is still going up and it is not that feasible to have that many clusters so we look at another methodology below:

### Average Silhouette Method

For the average silthouette method, we can see that 6 cluster is the sweet spot where there is not too little custer and the average silhouette width is maximized and clusters have the least overlap

```{r}
set.seed(1234)
fviz_nbclust(nga_wp_analysis.std, kmeans, method = "silhouette", k.max = 10) + theme_minimal() + ggtitle("Elbow cut method")
```

### Interpreting the dendrograms

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

### Visually-driven hierarchical clustering analysis

#### Transforming the data frame into a matrix

The data was loaded into a data frame, but it has to be a data matrix to make your heatmap.

The code chunk below will be used to transform nga_wp_analysis.std(normalized) into a data matrix.

```{r}
nga_wp_analysis_mat <- data.matrix(nga_wp_analysis.std)
```

#### Plotting interactive cluster heatmap using *heatmaply()*

In the code chunk below, the [*heatmaply()*](https://talgalili.github.io/heatmaply/reference/heatmaply.html) of [heatmaply](https://talgalili.github.io/heatmaply/) package is used to build an interactive cluster heatmap.

```{r}
heatmaply(nga_wp_analysis_mat,
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Nigeria by multi variate waterpoint attributes",
          xlab = "Waterpoint attributes",
          ylab = "Nigerian LGAs"
          )
```

### Mapping the clusters formed

With closed examination of the dendragram above, we have decided to retain 6 clusters.

[*cutree()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cutree.html) of R Base will be used in the code chunk below to derive a 6-cluster model.

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

```{r}
nga_wp_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
qtm(nga_wp_cluster, "CLUSTER")
```

As demonstrated in the map above, the clustering is rather fragmented and as hierarchical is not natively suited for geospatial clustering.

## Spatially Constrained Clustering: SKATER approach

### Converting into SpatialPolygonsDataFrame

As SKATER only allows the use of sp objects(Spatial Polygon Dataframe), we have to convert the original dataframe.

```{r}
nga_wp_sp <- as_Spatial(nga_wp)
```

### Computing Neighbour List

```{r}
nga_wp.nb <- poly2nb(nga_wp_sp)
summary(nga_wp.nb)
```

```{r}
plot(nga_wp_sp, 
     border=grey(.5))
plot(nga_wp.nb, 
     coordinates(nga_wp_sp), 
     col="blue", 
     add=TRUE)
```

### Computing minimum spanning tree

#### Calculating edge costs

Next, [*nbcosts()*](https://r-spatial.github.io/spdep/reference/nbcosts.html) of **spdep** package is used to compute the cost of each edge. This function compute this distance between each node using the data.frame with observations vector in each node.

```{r}
lcosts <- nbcosts(nga_wp.nb, nga_wp_analysis.std)
```

```{r}
nga_wp.w <- nb2listw(nga_wp.nb, 
                   lcosts, 
                   style="B")
summary(nga_wp.w)
```

### Computing minimum spanning tree

The minimum spanning tree is computed by mean of the [*mstree()*](https://r-spatial.github.io/spdep/reference/mstree.html) of **spdep** package as shown in the code chunk below.

```{r}
nga_wp.mst <- mstree(nga_wp.w)
```

Check if MST is computed and converted to MST class propertly

```{r}
class(nga_wp.mst )
```

we can also see the dimensions of the MST

```{r}
dim(nga_wp.mst)
```

```{r}
head(nga_wp.mst)
```

```{r}
plot(nga_wp_sp, border=gray(.5))
plot.mst(nga_wp.mst, 
         coordinates(nga_wp_sp), 
         col="blue", 
         cex.lab=0.3, 
         cex.circles=0.005, 
         add=TRUE)
```

### Computing spatially constrained clusters using SKATER method

```{r}
clust6 <- spdep::skater(edges = nga_wp.mst[,1:2], 
                 data = nga_wp_analysis.std, 
                 method = "euclidean", 
                 ncuts = 5)
```

```{r}
str(clust6)
```

```{r}
ccs6 <- clust6$groups
ccs6
```

```{r}
table(ccs6)
```

```{r}
plot(nga_wp_sp, border=gray(.5))
plot(clust6, 
     coordinates(nga_wp_sp), 
     cex.lab=.25,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

### 

```{r}
groups_mat <- as.matrix(clust6$groups)
nga_wp_spatialcluster <- cbind(nga_wp_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(nga_wp_spatialcluster, "SP_CLUSTER")
```

## Spatially Constrained Clustering: ClustGeo Method

### ClustGeo package

ClustGeo package is customized R package built for tackling the analysis of geospatial clustering. It also has an algorithm or method like ward's method for hierarchical clustering named `hclustgeo()`.

To keep things short, two matrices' dissimilarity are computed with a confounding variable alpha which can be between \[0,1\]. The second matrix provides the the dissimilarities in the **constraint space** while the first matrix can be non-euclidean and provides the dissimilarities in the **attribute/clustering variable space**. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with the first matrix and the homogeneity criterion calculated with second matrix.

The idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called `choicealpha()`.

### Ward-like hierarchical clustering: ClustGeo

To perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 6, 
            border = 2:5)
```

Note that the dissimilarity matrix must be an object of class `dist`, i.e. an object obtained with the function `dist()`.

#### Mapping the clusters formed

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=6))
```

```{r}
nga_wp_ngeo_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

```{r}
qtm(nga_wp_ngeo_cluster, "CLUSTER")
```

### Spatially Constrained Hierarchical Clustering

Before we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using [`st_distance()`](https://r-spatial.github.io/sf/reference/geos_measures.html) of sf package.

```{r}
dist <- st_distance(nga_wp,nga_wp)
distmat <- as.dist(dist)
```

Notice that `as.dist()` is used to convert the data frame into matrix.

Next, `choicealpha()` will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)
```

With reference to the two plots above, we can see the best balance for attribute space versus constraint space is found between 0.3 and 0.4, therefore we will go with 0.35 for alpha

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.35)
```

Next, `cutree()` is used to derive the cluster objecct.

```{r}
groups <- as.factor(cutree(clustG, k=6))
```

We will then join back the group list with *nga_wp (Nigerian waterpoint)* polygon feature data frame by using the code chunk below.

```{r}
nga_wp_Gcluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

```{r}
qtm(nga_wp_Gcluster, "CLUSTER")
```

## Visual Interpretation of Clusters

### Visualising individual clustering variable

```{r}
ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_functional)) +
  geom_boxplot()
```

The boxplot reveals that cluster 6 has the highest percentage of functional water points while cluster 1 seems to have the largest distribution. We then visualise all 8 variables together

```{r}

pf <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_functional))+
  geom_boxplot() +
  ggtitle("functional waterpoints(%)")

pn <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_nonfunctional))+
  geom_boxplot() +
  ggtitle("non-functional waterpoints(%)")


ph <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_handpump))+
  geom_boxplot() +
  ggtitle("handpump waterpoints(%)")

pr <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_rural))+
  geom_boxplot() +
  ggtitle("rural waterpoints(%)")

pu <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_usage1000))+
  geom_boxplot() +
  ggtitle("waterpoints(%)limit 1000")

pb <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = pct_usage_below_1000))+
  geom_boxplot() +
  ggtitle("waterpoints(%)limit < 1000")

ggarrange(pf, pn,ph,pr,pu,pb,
          ncol =2,
          nrow = 3)
```

From the box plot above, we can describe cluter 6 as the cluster with mainly handpump and mostly rural with most water point limit below 1000 and they have the more areas with higher percentages of functional water point.

In contrast, we can see that cluster 2 has more areas with relatively higher percentage of non-functional water points, it also has one of the lowest distributions for percentage of handpumps which means that likely has more mechanical pumps while it also has high amount of area with high percentage of waterpoints with usage limit at 1000. The higher water limit coupled with most water point being mechanical water points could have contributed to more non-functional water points and the clustering has helped to bring up this potential correlation.

### Multivariate Visualisation

Past studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package

```{r}
ggarrange(
ggparcoord(data = nga_wp_ngeo_cluster[nga_wp_ngeo_cluster$CLUSTER %in% c(1,2,3),], 
           columns = c(13:18), 
           scale = "globalminmax",
           alphaLines = 0.1,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of LGA waterpoint Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30,size = 5)),
ggparcoord(data = nga_wp_ngeo_cluster[nga_wp_ngeo_cluster$CLUSTER %in% c(4,5,6),], 
           columns = c(13:18), 
           scale = "globalminmax",
           alphaLines = 0.1,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of LGA waterpoint Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30,size = 5)),
  ncol = 1,
  nrow = 2
)

```

For this plot, we use the uniminmax to ensure every variable is scaled to \[0,1\]. WE can see that from this, [cluster 1]{.underline} on top left is least rural, and in general areas in the cluster have relatively low percentage of handpump waterpoints. with some outliers and the cluster has a mean of 50% functional waterpoints with the largest distribution for this value. The same observation applies as described in the observations above where cluster 6 in bottom right can be seen with the highest percentage of functional waterpoints, handpump water points and usage limit below 1000. Next, we take a look at the mean for each cluster:

```{r}
nga_wp_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(mean_functional = mean(pct_functional),
            mean_nonfunctional = mean(pct_nonfunctional),
            mean_handpump = mean(pct_handpump),
            mean_rural = mean(pct_rural),
            mean_usage1000 = mean(pct_usage1000),
            mean_usage_below_1000 = mean(pct_usage_below_1000))
```

Looking at the mean for each value in the clusters, we can safely say that they support the observations made above where mean of cluster 6 are high for rural, usage below 1000, handpump water points and functional percentage. While cluster 1 is the least rural with lowest amount of handpump. Another possible correlation to look at count be that the lower the percentage the handpump, the more likely that the percentage of functional waterpoints is lower.

## Conclusion

Based on what has been observed, we could quite safely say that spatially constrained clustering appears to be much better for working on the challenge and analysis of geospatial clusters. We can see that without the spatial constraints, the clusters appear more fragmented and might not be able to achieve the objective of allowing the analyst working on the project to draw the right insights. Below, we can take a final look between a SKATER clustered map and a hierarchical clustered map.

```{r}
groups_mat <- as.matrix(clust6$groups)
nga_wp_spatialcluster <- cbind(nga_wp_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
nga_wp_spatialcluster_map <- qtm(nga_wp_spatialcluster, "SP_CLUSTER", title = "SKATER clustering")

nga_wp_cluster_map <- qtm(nga_wp_cluster,
                   "CLUSTER", title = "Hierarchical clustering") 

tmap_arrange(nga_wp_spatialcluster_map, nga_wp_cluster_map,
             asp=NA, ncol=2)
```

### Credits

As usual, most credits goes to Prof Kam for his well structured in class exercise we can use to reference off for the exercise. Also many credits to our exemplary classmate Jordan for having such a well structured code for the rest of the class to refer to.
